{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2271/2271 [00:01<00:00, 1500.78it/s]\n",
      "100%|██████████| 2191/2191 [00:01<00:00, 1434.17it/s]\n",
      "100%|██████████| 2404/2404 [00:01<00:00, 1936.33it/s]\n",
      "100%|██████████| 2382/2382 [00:01<00:00, 1609.26it/s]\n",
      "100%|██████████| 2512/2512 [00:01<00:00, 2132.04it/s]\n",
      "100%|██████████| 2274/2274 [00:01<00:00, 1999.33it/s]\n",
      "100%|██████████| 474/474 [00:00<00:00, 1715.82it/s]\n",
      "100%|██████████| 437/437 [00:00<00:00, 2163.89it/s]\n",
      "100%|██████████| 553/553 [00:00<00:00, 2217.81it/s]\n",
      "100%|██████████| 501/501 [00:00<00:00, 2124.87it/s]\n",
      "100%|██████████| 525/525 [00:00<00:00, 2392.22it/s]\n",
      "100%|██████████| 510/510 [00:00<00:00, 2306.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset and preparing it for training\n",
    "train_path = '../archive/seg_train/seg_train/'\n",
    "test_path = '../archive/seg_test/seg_test/'\n",
    "\n",
    "# Loading the dataset\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_images(path):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for folder in os.listdir(path):\n",
    "        files = os.listdir(path + folder)\n",
    "        for file in tqdm(files):\n",
    "            img = cv2.imread(path + folder + '/' + file)\n",
    "            img = cv2.resize(img, (150, 150))\n",
    "            X.append(img)\n",
    "            y.append(folder)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = load_images(train_path)\n",
    "X_test, y_test = load_images(test_path)\n",
    "\n",
    "classes_names = np.unique(y_train)\n",
    "\n",
    "# Encoding the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# One hot encoding the target variable\n",
    "y_train_encoded = to_categorical(y_train_encoded)\n",
    "y_test_encoded = to_categorical(y_test_encoded)\n",
    "\n",
    "# Splitting the training set into training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=0)\n",
    "\n",
    "# Normalizing the images\n",
    "X_train = X_train / 255\n",
    "X_val = X_val / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,781,126\n",
      "Trainable params: 66,438\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 16:42:01.658367: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-17 16:42:01.743420: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60/351 [====>.........................] - ETA: 8:18 - loss: 1.4726 - accuracy: 0.4245"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_checkpoint = ModelCheckpoint('vgg16_data_augmented.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_val, y_val), epochs=10, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Plotting the accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model and evaluating it on the test set\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('vgg16_data_augmented.h5')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# f1 score, precision, recall, accuracy, confusion matrix, classification report, and ROC curve\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_curve, auc\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1), average='weighted')\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1), average='weighted')\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1), average='weighted')\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1))\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# ROC Curve\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_encoded[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.plot(fpr[i], tpr[i], label=classes_names[i] + ' (AUC = ' + str(roc_auc[i]) + ')')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1), target_names=classes_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(np.argmax(y_test_encoded, axis=1), np.argmax(predictions, axis=1))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes_names, yticklabels=classes_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to displaying random predictions from the dataset with their images and predictions\n",
    "\n",
    "def display_random_predictions(X, y, predictions, classes_names, number_of_predictions=5):\n",
    "    plt.figure(figsize=(15, 20))\n",
    "\n",
    "    for class_name in classes_names:\n",
    "        for i in range(number_of_predictions):\n",
    "            index = np.random.choice(np.where(y == class_name)[0])\n",
    "            plt.subplot(len(classes_names), number_of_predictions, number_of_predictions * list(classes_names).index(class_name) + i + 1)\n",
    "            plt.imshow(X[index])\n",
    "            plt.title(\"Actual: \" + class_name + \"\\nPredicted: \" + label_encoder.classes_[np.argmax(predictions[index])])\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "display_random_predictions(X_test, y_test, predictions, classes_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
